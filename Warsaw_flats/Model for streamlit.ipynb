{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/data_clean_removed.csv')\n",
    "dataset.drop([\"Unnamed: 0\"],inplace= True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.replace({'elevatoe': {1: 'jest', 0: 'nie ma'}}, inplace=True)\n",
    "dataset.replace({'Parkingplace': {1: 'jest', 0: 'nie ma'}}, inplace=True)\n",
    "dataset.replace({'balkon': {1: 'jest', 0: 'nie ma'}}, inplace=True)\n",
    "dataset.replace({'taras': {1: 'jest', 0: 'nie ma'}}, inplace=True)\n",
    "dataset.replace({'ogrdek': {1: 'jest', 0: 'nie ma'}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Space</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Market</th>\n",
       "      <th>Year</th>\n",
       "      <th>elevator</th>\n",
       "      <th>Parkingplace</th>\n",
       "      <th>balkon</th>\n",
       "      <th>taras</th>\n",
       "      <th>ogrdek</th>\n",
       "      <th>district</th>\n",
       "      <th>street</th>\n",
       "      <th>level</th>\n",
       "      <th>max_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000000</td>\n",
       "      <td>560</td>\n",
       "      <td>4</td>\n",
       "      <td>wtórny</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jest</td>\n",
       "      <td>jest</td>\n",
       "      <td>jest</td>\n",
       "      <td>jest</td>\n",
       "      <td>Wawer</td>\n",
       "      <td>Patriotów</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000000</td>\n",
       "      <td>560</td>\n",
       "      <td>4</td>\n",
       "      <td>wtórny</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jest</td>\n",
       "      <td>jest</td>\n",
       "      <td>jest</td>\n",
       "      <td>jest</td>\n",
       "      <td>Wawer</td>\n",
       "      <td>Patriotów</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21350100</td>\n",
       "      <td>487</td>\n",
       "      <td>10</td>\n",
       "      <td>wtórny</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>jest</td>\n",
       "      <td>nie ma</td>\n",
       "      <td>nie ma</td>\n",
       "      <td>nie ma</td>\n",
       "      <td>Śródmieście</td>\n",
       "      <td>Elektryczna</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19900000</td>\n",
       "      <td>487</td>\n",
       "      <td>6</td>\n",
       "      <td>wtórny</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>jest</td>\n",
       "      <td>nie ma</td>\n",
       "      <td>nie ma</td>\n",
       "      <td>nie ma</td>\n",
       "      <td>Mokotów</td>\n",
       "      <td>Cybulskiego</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  Space  Rooms  Market  Year  elevator Parkingplace  balkon  \\\n",
       "0   4000000    560      4  wtórny  2015         1         jest    jest   \n",
       "1   4000000    560      4  wtórny  2015         1         jest    jest   \n",
       "2  21350100    487     10  wtórny  2021         1         jest  nie ma   \n",
       "3  19900000    487      6  wtórny  2001         1         jest  nie ma   \n",
       "\n",
       "    taras  ogrdek      district        street  level  max_level  \n",
       "0    jest    jest         Wawer     Patriotów      3          3  \n",
       "1    jest    jest         Wawer     Patriotów      3          3  \n",
       "2  nie ma  nie ma   Śródmieście   Elektryczna      6          6  \n",
       "3  nie ma  nie ma       Mokotów   Cybulskiego      5          5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dummies = pd.get_dummies(dataset,columns=['Market','street','district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(dataset_dummies.drop(['Price'],axis=1),dataset_dummies['Price'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 486, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'jest'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'jest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ja\\Desktop\\python\\data science\\git\\Warsaw_flats\\Model for streamlit.ipynb Komórka 8\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ja/Desktop/python/data%20science/git/Warsaw_flats/Model%20for%20streamlit.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m100\u001b[39m,\u001b[39m200\u001b[39m,\u001b[39m300\u001b[39m,\u001b[39m400\u001b[39m,\u001b[39m500\u001b[39m,\u001b[39m600\u001b[39m,\u001b[39m700\u001b[39m,\u001b[39m800\u001b[39m,\u001b[39m900\u001b[39m,\u001b[39m1000\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m,\u001b[39m10\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m0.1\u001b[39m,\u001b[39m0.2\u001b[39m,\u001b[39m0.3\u001b[39m,\u001b[39m0.4\u001b[39m,\u001b[39m0.5\u001b[39m,\u001b[39m0.6\u001b[39m,\u001b[39m0.7\u001b[39m,\u001b[39m0.8\u001b[39m,\u001b[39m0.9\u001b[39m,\u001b[39m1\u001b[39m]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ja/Desktop/python/data%20science/git/Warsaw_flats/Model%20for%20streamlit.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m search \u001b[39m=\u001b[39m RandomizedSearchCV(gbr,param_distributions\u001b[39m=\u001b[39mparams,cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,return_train_score\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ja/Desktop/python/data%20science/git/Warsaw_flats/Model%20for%20streamlit.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m search\u001b[39m.\u001b[39;49mfit(x_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:486\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_state()\n\u001b[0;32m    482\u001b[0m \u001b[39m# Check input\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m# Since check_array converts both X and y to the same dtype, but the\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[39m# trees use different types for X and y, checking them separately.\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    487\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mDTYPE, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    488\u001b[0m )\n\u001b[0;32m    490\u001b[0m sample_weight_is_none \u001b[39m=\u001b[39m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    492\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ja\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'jest'"
     ]
    }
   ],
   "source": [
    "gbr  = GradientBoostingRegressor()\n",
    "params = {'n_estimators':[100,200,300,400,500,600,700,800,900,1000],'max_depth':[1,2,3,4,5,6,7,8,9,10],'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n",
    "search = RandomizedSearchCV(gbr,param_distributions=params,cv=5,return_train_score=False)\n",
    "\n",
    "search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'gbr_model.sav'\n",
    "pickle.dump(best_gbr, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "159697b668ff5a13ceb2c063ed8de9b4789b2bc43cbb8e1eb8abcd7959a6dfc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
